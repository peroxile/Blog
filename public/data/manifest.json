[
  {
    "title": "Linux 101: Core Root Subdirectories",
    "filename": "linuxsys.md",
    "date": "2025-12-23",
    "excerpt": "This entails the minimal Linux filesystem one needs to master if new to the world of Linux. After further research, I drafted this piece to help anyon...",
    "content": "# Linux 101: Core Root Subdirectories\n\nThis entails the minimal Linux filesystem one needs to master if new to the world of Linux. After further research, I drafted this piece to help anyone who's interested in mastering the fundamentals of Linux systems. \n\n**`/bin`** Contains ready-to-run programs (also known as executables), including most of the basic Unix commands such as `ls` and `cp`. Most programs in `/bin` are in binary format, having been created by a C compiler, though some are shell scripts in modern systems.\n\n**`/dev`** Contains device files that represent hardware devices and special files. Understanding device files is crucial for storage management, permissions, and system configuration.\n\n**`/etc`** This core system configuration directory (pronounced \"EHT-see\") contains user passwords, boot configurations, device settings, networking parameters, and other setup files. Many items in `/etc` are specific to the machine's hardware. For example, `/etc/X11` contains graphics card and window system configurations. Key administrative files include `/etc/shadow`, `/etc/passwd`, `/etc/sudoers`, and `/etc/hostname`.\n\n**`/home`** Holds personal directories for regular users. Most Unix installations conform to this standard, with each user having a dedicated directory like `/home/username`.\n\n**`/lib`** An abbreviation for library, this directory holds library files containing code that executables can use. There are two types of libraries: static and shared. The `/lib` directory contains only shared libraries, while other directories such as `/usr/lib` contain both varieties as well as auxiliary files.\n\n**`/proc`** Provides system statistics through a browseable directory-and-file interface. Much of the `/proc` subdirectory structure on Linux is unique, though many other Unix variants have similar features. The `/proc` directory contains information about currently running processes and some kernel parameters. It's a virtual filesystem that reflects the current system state in real-time.\n\n**`/sys`** Similar to `/proc`, it provides a device and system interface. This directory exposes kernel and driver information in a hierarchical structure, making it essential for advanced system troubleshooting and monitoring.\n\n**`/sbin`** The place for system executables. Programs in `/sbin` directories relate to system management, so regular users usually do not have `/sbin` components in their command paths. Many utilities found here require root privileges to execute properly.\n\n**`/tmp`** A storage area for smaller, temporary files that you don't care much about. Any user may read from and write to `/tmp`, but users cannot access other users' files there. Many programs use this directory as a workspace. Important note: Don't store critical data in `/tmp` because most distributions clear it on boot, and some even remove old files periodically. Also, don't let `/tmp` fill up with garbage since it's usually shared with critical system components.\n\n**`/usr`** Although pronounced \"user,\" this subdirectory contains no user files. Instead, it holds a large directory hierarchy containing the bulk of the Linux system. Many directory names in `/usr` mirror those in the root directory (like `/usr/bin` and `/usr/lib`), holding the same types of files. This separation is primarily historical—in the past, it helped keep root directory space requirements low.\n\nThe `/usr` directory contains substantial content:\n\n- **`/usr/bin`** Contains most user-facing programs and utilities.\n- **`/usr/sbin`** Contains system administration programs.\n- **`/usr/lib`** Holds libraries used by programs in `/usr/bin` and `/usr/sbin`.\n- **`/usr/include`** Contains header files used by the C compiler.\n- **`/usr/info`** Contains GNU info manuals.\n- **`/usr/local`** Where administrators can install their own software, isolated from the main system.\n- **`/usr/man`** Contains manual pages.\n- **`/usr/share`** Contains files that should work on other Unix machines with no loss of functionality.\n\n**`/var`** The variable subdirectory, where programs record runtime information. System logging, user tracking, caches, and other files that system programs create and manage are stored here. You'll notice a `/var/tmp` directory here, which the system doesn't wipe on boot, making it slightly safer than `/tmp` for temporary data.\n\n#### Additional Root Subdirectories\n\n**`/boot`** Contains kernel boot loader files. These files pertain only to the very early stage of the Linux startup procedure; you won't find information about how Linux starts its services in this directory.\n\n**`/media`** A base attachment point for removable media such as flash drives, found in many modern distributions.\n\n**`/opt`** May contain additional third-party software. Many systems don't use `/opt`, but it's a standard location for commercial software packages.\n\n**`/root`** The home directory for the root user, separate from `/home` for security reasons.\n\n**`/mnt`** Traditionally used as a temporary mount point for filesystems, though `/media` has become more common for removable media.\n\n**References:**\nHow Linux Works -- What every SuperUser Should Know - Brain Ward (2ND EDITION)\n\n\n\n\n"
  },
  {
    "title": "Hard Nut in shell:  Buiding Automation workflow",
    "filename": "hardnutsh.md",
    "date": "2025-12-16",
    "excerpt": "Building and automating tasks can be considered critical at some point if much....",
    "content": "# Hard Nut in shell:  Buiding Automation workflow \n\nBuilding and automating tasks can be considered critical at some point if much.... \n\n\n\nThe math behind automating the probability of improving a job:\n\n```bash\n\n\nLet F = number of failed jobs in the period.\nLet T = total jobs in period.\nFailure rate = F/T \n\nExpressed as a percentage\n(F / T) × 100\n\nA displayed value of **25%** implies:\n\nF / T = 0.25\n\n- Example instantiation: if 25 jobs failed out of 100 total, or 5 out of 20, or any pair maintaining the 1:4 ratio.\n\nProbability of “improving” the rate cannot be computed from the metric alone.  \nA probability requires a defined stochastic model: distributions of job outcomes over time, independence assumptions, and historical variance.  \nThe screenshot provides only aggregated counts, which are insufficient to derive any predictive probability.\n\n```"
  },
  {
    "title": "Mastering Critical Web Application Security Risks",
    "filename": "sec.md",
    "date": "2025-12-11",
    "excerpt": "I've been actually studying the OWASP Top 10 and here is a comprehensive note to master the critical security risks that threatens modern web applicat...",
    "content": "# Mastering Critical Web Application Security Risks\n\nI've been actually studying the OWASP Top 10 and here is a comprehensive note to master the critical security risks that threatens modern web applications and learn practical mitigation strategies.\n\n# A01:2021 - Broken Access Control \n## Overview\nBroken Access control has risen from fifth position to become the number one security risk in 2021. This category occurs when users can act outside of their intended permissions, allowing unauthorized access to sensitive data, modification of user data or execution of privileged functions.\n\n\n## Common Vulnerabilities\n\n### 1. Insecure Direct Object References (IDOR)\nOccurs when applications expose internal implementation objects like database keys in URLS or parameters. Attackers can manipulate these references to access unauthorized data.\n\nExample: \n``` https://example.com/account?id=12345```\n\n\n### 2. Missing Function Level Access Control\nAdministrative functions are not properly protected, allowing regular users to access privileged operations by simply navigating to the right URL or API endpoint.\n\n\n### 3. Path Traversal\nAttackers manipulate file paths to access files and directories outside the intended directory structure, potentially reading sensitive system files.\n\n\n## Real-World\nAccess control failures can lead to severe consequences including unauthorized data disclosure, data modification or destruction, business function abuse, and complete account takeover. In 2019, a major social media platform experienced a data breach affecting 540 million user records due to improperly configured access controls on cloud storage.\n\n\n## Mitigation Strategies\nImplement these security controls:\n- Enforce access controls at the trusted server-side code or severless API\n- Use Deny-by-default principle: deny access except for public resources \n- Implement attribute-based or role-based access control(RBAC/ABAC)\n- Use indirect object references (random tokens) instead of exposing database keys \n- Disable directory listing and ensure metadata is not accessible\n- Log access control failures and alert administrators for repeated failures.\n- Rate limit API access to minimize automated attacks.\n\n\n## Testing Techniques \nTest for broken access control by attempting to access resources with different user roles, manipulating URL parameters, testing API endpoints with different authentication tokens, and using automated tools like OWASP ZAP or Burp Suite to identify authorization bypass opportunities.\n\n\n# A02:2021 - Cryptographic Failures\n## Overview\n\nPreviously known as Sensitive Data Exposure, this category focuses on failures related to cryptography that often lead to exposure of sensitive data. It encompasses issues with encryption, hashing, key management, and secure communication protocols.\n\n## Common Vulnerabilities\n\n### 1. Transmitting Data in Clear Text\nUsing protocols like HTTP, SMTP, FTP without TLS/SSL encryption exposes sensitive data during transmission. This makes data vulnerable to man-in-the-middle attacks and network sniffing.\n\n\n### 2. Weak or Outdated Cryptographic Algorithms\nUsing deprecated algorithms like MD5, SHA1 for hashing, or DES, RC4 for encryption. These algorithms have known vulnerabilities and can be broken with modern computing power.\n\n\n### 3. Improper Key Management\nHardcoded encryption keys, using default keys, storing keys in version control, or failing to rotate keys regularly. Poor key management can compromise even the strongest encryption.\n\n\n### 4. Insecure Storage of Sensitive Data\nStoring passwords, credit includes improper database encryption and unencrypted backups.\ncard numbers, or personal information without proper encryption at rest. This i\n\n\n## Real-World Impact\nCryptographic failures have resulted in massive data breaches. In 2013, a major retailer suffered a breach affecting 40 million credit card due to weak encryption. In 2017, a credit reporting agency's breach exposed 147 million records partly due to unencrypted sensitive data.\n\n\n## Mitigation Strategies \n## Data Protection Best Practices\n- Classify data and apply appropriate protection based on sensitivity\n- Encrypt all sensitive data at rest using algorithms (AES-256)\n- Enforce TLS 1.2 or higher for all data in transit with proper certificate validation.\n- Use strong adaptive hashing algorithms like Argon2, bcrypt, or PBKDF2 for passwords\n- Disable caching for responses containing sensitive data\n- Store cryptographic keys in secure key management systems (KMS)\n- Implement Perfect Forward Secrecy (PFS) cipher suites.\n- Use authenticated encryption with associated data (AEAD)\n\n\n## Testing Approaches \nAccess cryptographic implementation by reviewing TLS configuration with tools like SSL Labs, examining password storage mechanisms, verifying encryption at rest, testing for mixed content issues, and analyzing network traffic for cleartext transmission of sensitive data.\n\n\n# A03:2021 - Injection \n## Overview\nInjection flaws occur when untrusted data is sent to an interpreter as part of a command or query. This category now includes Cross-Site Scripting(XSS), previously a separate category. Injection attacks can result in data loss, corruption, unauthorized access, and complete system compromise.\n\n\n## Types of Injection Attacks\n### 1. SQL Injection (SQLi)\nAttackers insert malicious SQL statements into application queries, potentially accessing, modifying, or deleting database data. This remains one of the most dangerous web application vulnerabilities.\n\n\n**Vulnerable Code Example:**\n``` SELECT * FROM users WHERE username = '' + username + '' ```\n\n\n**Attack Payload**\n``` username = admin' OR '1'='1```\n\n\n### 2. Cross-Site Scripting (XSS)\nInjecting malicious scripts into web pages viewed by other users. XSS attacks can steal session tokens , deface websites, or redirect users to malicious sites. \n\n\n## Types of XSS: \n- Reflected XSS: Script comes from current HTTP request \n- Stored XSS: Script permanently stored on target server \n- DOM-based XSS: Vulnerability exists in client-side code\n\n### 3. Command Injection\nExecuting arbitrary systems commands on the host operating system. This can lead to complete system compromise, allowing attackers to read files, install malware, or pivot to other systems. \n\n\n### 4. LDAP, XPath, and NOSQL Injection \nSimilar to SQL injection but targeting LDAP directories, XML queries, or NOSQL databases. Each has unique syntax but shares the common pattern of injecting malicious input into queries. \n\n\n## Mitigation Strategies\n## Defense in Depth Approach:\n- Use parametrized queries (prepared statements) for all database access\n- Implement input validation using whitelist approach for all user inputs\n- Use Object Relational Mapping (ORM) frameworks that prevent SQL injection\n- Escape special characters in outputs using context-appropriate encoding \n- Implement Content Security Policy (CSP) to prevent XSS attacks\n- Use auto-escaping template systems that escape by default\n- Apply principle of least privilege to database accounts\n- Use Web Application Firewalls (WAF) as an additional defense layer.\n\n\n## Testing Methodology\nTest for injection vulnerabilities using both manual and automated approaches. Use fuzzing techniques with special characters, employ SQL injection tools like sqlmap, test for XSS in all input filed and URL parameters, and conduct code reviews focusing on database queries and user input handling.\n\n\n# A03:2021 - Insecure Design \n## Overview\nInsecure Design is a new category for 2021, focusing on risks related to design and architectural flaws. It represents missing or ineffective security controls in the design phase. This differs from insecure implementation, as even perfect implementation\ncannot fix an insecure design.\n\n\n## Key Concepts \n### Design vs Implementation\nInsecure design focuses on flaws in the architecture and business logic before code is written. Insecure implementation refers to bugs and vulnerabilities introduced during coding. Both are critical, but insecure design requires different remediation approaches.\n\n\n### Threat Modeling \nA structured approach to identifying, quantifying, and addressing security threats. Effective threat modeling during the design phase helps identify potential attack vectors and design appropriate security controls before development begins.\n\n## Common Design Flaws\n\n### 1. Missing Business Logic Security Controls \nFailing to implement rate limiting on critical functions like password reset, allowing unlimited purchase of limited inventory, or missing transaction rollback mechanisms that could lead to  inconsistent states.\n\n\n### Lack of Secure Development Lifecycle (SDL)\nNot integrating security practices throughout the development process, including requirements gathering, design flaws, security testing, and deployment procedures. SDL ensures security is considered at every stage.\n\n\n### Insufficient Security Requirements \nFailing to define clear security requirements during the requirements phase, leading o missing authentication mechanisms, inadequate access controls, or insufficient data protection.\n\n\n## Real-World Examples\nA cinema chain application allows group booking discounts but fails to validate that the the number of tickets doesn't exceed the number of seats. An attacker exploits this by booking negative tickets, receiving refund instead of payment. This is a business logic flaw resulting from insecure design.\n\n\n## Mitigation Strategies \n### Secure Design Principles: \n- Establish and use a secure development lifecycle with security professionals.\n- Use established secure design patterns and reference architectures.\n- Conduct threat modeling for critical authentication, access control, and business logic.\n- Integrate security language and controls into user stories. \n- Implement plausibility checks at every tier of the application.\n- Write unit and integration tests to validate critical flows.\n- Segregate tier layers based on exposure and protection needs.\n- Limit resource consumption by user or service with appropriate controls \n\n\n## Secure by Design Culture\nBuilding secure applications requires organizational commitment to security-first thinking. This includes training development teams on secure coding practices, conducting regular security design reviews, and fostering collaboration between development, security, and operations teams throughout the entire project lifecycle.\n\n\n"
  }
]